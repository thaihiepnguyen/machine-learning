{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3d6fe8",
   "metadata": {},
   "source": [
    "## Spam Filter using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa84367",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6eee743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install -U scikit-learn\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed317e2",
   "metadata": {},
   "source": [
    "### Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0527322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "0         ham  Go until jurong point, crazy.. Available only ...\n",
       "1         ham                      Ok lar... Joking wif u oni...\n",
       "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         ham  U dun say so early hor... U c already then say...\n",
       "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...       ...                                                ...\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "spam_df = pd.read_csv(\"spam.csv\")\n",
    "spam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d937a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spam_df.Message\n",
    "Y = spam_df['Category'].apply(lambda x: 1 if x == 'spam' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c815766",
   "metadata": {},
   "source": [
    "### 0. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8313c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_text = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "X_new = X.apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec39a8a",
   "metadata": {},
   "source": [
    "### 1. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b087ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "def nb_train_test_split(X, Y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33)\n",
    "    x_train_count = cv.fit_transform(x_train.values).toarray()\n",
    "    x_test_count = cv.transform(x_test.values).toarray()\n",
    "    y_train_array = np.array(y_train)\n",
    "    y_test_array = np.array(y_test)\n",
    "    return x_train_count, x_test_count, y_train_array, y_test_array\n",
    "\n",
    "x_train, x_test, y_train, y_test = nb_train_test_split(X_new,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b6c6a",
   "metadata": {},
   "source": [
    "### Bayes Theorem\n",
    "\n",
    "Bayes formulation\n",
    "$$\\begin{equation}\n",
    "P\\left(A|B\\right)= \\dfrac{P\\left(B|A\\right)P\\left(A\\right)}{P\\left(B\\right)}\n",
    "\\end{equation}$$\n",
    "\n",
    "If $B$ is our data $\\mathcal{D}$, $A$ and $w$ are parameters we need to estimate:\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\underbrace{P(w|\\mathcal{D})}_{Posterior}= \\dfrac{1}{\\underbrace{P(\\mathcal{D})}_{Normalization}} \\overbrace{P(\\mathcal{D}|w)}^{\\text{Likelihood}} \\overbrace{P(w)}^{Prior}\n",
    "    \\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d684e6f",
   "metadata": {},
   "source": [
    "### 2. Train Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "baf2a2a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesModel:\n",
    "    def __init__(self):\n",
    "        self.hist = dict()\n",
    "        self.mean = dict()\n",
    "        self.std = dict()\n",
    "        \n",
    "    def _gauss(self, std, mean, x):\n",
    "        f = (1 / (std * math.sqrt(2 * math.pi))) * math.exp(-((x - mean)**2) / (2 * std**2))\n",
    "        return f\n",
    "    \n",
    "    def _likelihood(self, data, hypo):\n",
    "        std = self.std[hypo]\n",
    "        mean = self.mean[hypo]\n",
    "\n",
    "        res = 1\n",
    "        n_attr = len(data)\n",
    "\n",
    "        for j in range(n_attr):\n",
    "            p_xi_hypo = self._gauss(std[j], mean[j], data[j])\n",
    "            res *= p_xi_hypo\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def _update(self, data):\n",
    "        for hypo in self.hist.keys():\n",
    "            self.hist[hypo] = self._likelihood(data, hypo) * self.hist[hypo]\n",
    "\n",
    "        s = sum(self.hist.values())\n",
    "        for hypo in self.hist.keys():\n",
    "            self.hist[hypo] = self.hist[hypo] / s\n",
    "         \n",
    "    def _max_hypo(self):\n",
    "        \"\"\"\n",
    "        Find label with the highest probability\n",
    "        -----------\n",
    "        return: label of data\n",
    "        \"\"\" \n",
    "\n",
    "        max_hypo = 0\n",
    "        for hypo in self.hist.keys():\n",
    "            if self.hist[hypo] > self.hist[max_hypo]:\n",
    "                max_hypo = hypo\n",
    "        return max_hypo\n",
    "    \n",
    "    def _predict(self, data):\n",
    "        \"\"\"\n",
    "        Predict label for only 1 data sample\n",
    "        ------------\n",
    "        Parameters:\n",
    "        data: data sample\n",
    "        -----------\n",
    "        return: label of data\n",
    "        \"\"\" \n",
    "        self._update(data)\n",
    "        return self._max_hypo()\n",
    "        \n",
    "    def predict(self, data):\n",
    "        \"\"\"Parameters:\n",
    "        Data: test data\n",
    "        ----------\n",
    "        return labels of test data\"\"\"\n",
    "        \n",
    "        pred = np.zeros(len(data))\n",
    "        for i, c in enumerate(data):\n",
    "            pred[i] = self._predict(c)\n",
    "        return pred\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        pred = self.predict(X_test)\n",
    "        return sum(y_test == pred) / len(pred)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Parameters:\n",
    "        X: training data\n",
    "        y: labels of training data\"\"\"\n",
    "\n",
    "        n = len(X)\n",
    "        # number of spam species\n",
    "        n_species = len(set(y))\n",
    "\n",
    "        for hypo in range(0, n_species):\n",
    "\n",
    "            y_hypo = [label == hypo for label in y]\n",
    "\n",
    "            rows = X[y_hypo]\n",
    "\n",
    "            count_each_hypo = np.sum(y_hypo)\n",
    "\n",
    "            # Prior\n",
    "            probability = count_each_hypo / n\n",
    "\n",
    "            self.hist[hypo] = probability\n",
    "\n",
    "            # Each hypothesis represented by its mean and standard derivation\n",
    "            # mean and standard derivation should be calculated for each column (or each attribute)\n",
    "\n",
    "            count_of_attribute = len(X[0])\n",
    "\n",
    "            mean_hypo = [0.0] * count_of_attribute\n",
    "            std_hypo = [0.0] * count_of_attribute\n",
    "\n",
    "            # traversal and calculate mean, std for each column (attribute)\n",
    "            for j in range(count_of_attribute):\n",
    "                col_j = [row[j] for row in X]\n",
    "                mean_hypo[j] = sum(col_j) / len(col_j)\n",
    "                std_hypo[j] = (sum((x - mean_hypo[j])**2 for x in col_j) / len(col_j))**0.5\n",
    "\n",
    "            self.mean[hypo] = mean_hypo\n",
    "            self.std[hypo] = std_hypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83d7c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayesModel()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e6e9c",
   "metadata": {},
   "source": [
    "### 3. Evaluate Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ae33473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rt/4tkn4rnd08398_svvty00h6m0000gn/T/ipykernel_24607/883363210.py:20: RuntimeWarning: overflow encountered in double_scalars\n",
      "  res *= p_xi_hypo\n",
      "/var/folders/rt/4tkn4rnd08398_svvty00h6m0000gn/T/ipykernel_24607/883363210.py:30: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  self.hist[hypo] = self.hist[hypo] / s\n",
      "/var/folders/rt/4tkn4rnd08398_svvty00h6m0000gn/T/ipykernel_24607/883363210.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  res *= p_xi_hypo\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7dc6f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our gaussian naive bayes model:  0.8814573137574769\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our gaussian naive bayes model: \", accuracy_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
